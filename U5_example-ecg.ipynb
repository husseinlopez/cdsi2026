{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# U5: Ejemplo de detección de arritmias con señales ECG\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/husseinlopez/cdsi2026/blob/main/U5_example-ecg.ipynb)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#!pip install wfdb heartpy scipy scikit-learn pandas numpy matplotlib seaborn"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# system\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# data\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# ECG / signal\nimport wfdb\nimport heartpy as hp\nfrom scipy.signal import welch\nfrom scipy.interpolate import interp1d\n\n# machine learning\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Datasets"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Usamos dos bases de datos de PhysioNet, descargables directamente con `wfdb` sin necesidad de credenciales:\n\n- **MIT-BIH Arrhythmia Database** (`mitdb`): 48 registros de ECG ambulatorio de 30 minutos con anotaciones beat-by-beat de arritmias. 360 Hz. https://physionet.org/content/mitdb/1.0.0/\n- **MIT-BIH Normal Sinus Rhythm Database** (`nsrdb`): 18 registros de sujetos sin arritmias significativas. 128 Hz. https://physionet.org/content/nsrdb/1.0.0/\n\nLa tarea de clasificación es **ritmo normal vs. arritmia**, directamente relevante al contexto de wearables como Fitbit y Oura mencionados en clase."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MIT-BIH Arrhythmia: records with predominantly normal rhythm\n# and records with clear arrhythmias — balanced subset for the example\nARRHYTHMIA_RECORDS = ['100', '101', '104', '105', '106',\n                      '108', '109', '111', '112', '113']\n\n# MIT-BIH Normal Sinus Rhythm\nNORMAL_RECORDS     = ['16265', '16272', '16273', '16420', '16483',\n                      '16539', '16773', '16786', '16795', '17052']\n\nSR_ARRHYTHMIA = 360  # Hz\nSR_NORMAL     = 128  # Hz"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Loading a single record"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_record(record_id, db_name, sample_rate):\n    \"\"\"Download one record from PhysioNet and return the MLII channel + sample rate.\"\"\"\n    record = wfdb.rdrecord(record_id,\n                           pn_dir=db_name,\n                           sampfrom=0,\n                           sampto=sample_rate * 60 * 10)  # first 10 minutes\n    # use channel 0 (MLII) for all records\n    ecg = record.p_signal[:, 0]\n    return ecg\n\n# load one arrhythmia record and one normal record\necg_arr = load_record('106', 'mitdb', SR_ARRHYTHMIA)\necg_nsr = load_record('16265', 'nsrdb', SR_NORMAL)\n\nprint(f'Arrhythmia record — samples: {len(ecg_arr)}, duration: {len(ecg_arr)/SR_ARRHYTHMIA/60:.1f} min')\nprint(f'Normal record     — samples: {len(ecg_nsr)}, duration: {len(ecg_nsr)/SR_NORMAL/60:.1f} min')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exploratory analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 1, figsize=(14, 5), sharex=False)\n\n# 10-second windows for visualization\nt_arr = np.arange(10 * SR_ARRHYTHMIA) / SR_ARRHYTHMIA\nt_nsr = np.arange(10 * SR_NORMAL) / SR_NORMAL\n\naxes[0].plot(t_arr, ecg_arr[:10 * SR_ARRHYTHMIA], color='tomato', linewidth=0.8)\naxes[0].set_title('MIT-BIH Arrhythmia — record 106 (10 s)', fontsize=11)\naxes[0].set_ylabel('mV')\n\naxes[1].plot(t_nsr, ecg_nsr[:10 * SR_NORMAL], color='steelblue', linewidth=0.8)\naxes[1].set_title('MIT-BIH Normal Sinus Rhythm — record 16265 (10 s)', fontsize=11)\naxes[1].set_ylabel('mV')\naxes[1].set_xlabel('time (s)')\n\nfor ax in axes:\n    sns.despine(ax=ax)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Preprocessing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The two databases have different sampling rates (360 Hz vs 128 Hz). We resample all signals to a common rate before filtering and peak detection."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from scipy.signal import resample\n\nTARGET_SR = 256  # common target sample rate (Hz)\n\ndef preprocess(ecg, original_sr, target_sr=TARGET_SR):\n    \"\"\"Resample to target_sr and apply bandpass filter.\"\"\"\n    # resample\n    n_samples = int(len(ecg) * target_sr / original_sr)\n    ecg_resampled = resample(ecg, n_samples)\n    # bandpass filter 0.5–40 Hz\n    ecg_filtered = hp.filter_signal(ecg_resampled,\n                                    cutoff=[0.5, 40],\n                                    sample_rate=target_sr,\n                                    filtertype='bandpass')\n    return ecg_filtered\n\necg_arr_p = preprocess(ecg_arr, SR_ARRHYTHMIA)\necg_nsr_p = preprocess(ecg_nsr, SR_NORMAL)\n\nprint(f'After preprocessing — arrhythmia: {len(ecg_arr_p)} samples')\nprint(f'After preprocessing — normal:     {len(ecg_nsr_p)} samples')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# show effect of preprocessing on 5-second window\nn = 5 * TARGET_SR\nt = np.arange(n) / TARGET_SR\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 5))\n\naxes[0, 0].plot(t, ecg_arr[:n * SR_ARRHYTHMIA // TARGET_SR], color='gray', linewidth=0.8)\naxes[0, 0].set_title('arrhythmia — raw', fontsize=10)\naxes[0, 1].plot(t, ecg_arr_p[:n], color='tomato', linewidth=0.8)\naxes[0, 1].set_title('arrhythmia — filtered (256 Hz)', fontsize=10)\n\naxes[1, 0].plot(t, ecg_nsr[:n * SR_NORMAL // TARGET_SR], color='gray', linewidth=0.8)\naxes[1, 0].set_title('normal — raw', fontsize=10)\naxes[1, 1].plot(t, ecg_nsr_p[:n], color='steelblue', linewidth=0.8)\naxes[1, 1].set_title('normal — filtered (256 Hz)', fontsize=10)\n\nfor ax in axes.flatten():\n    ax.set_ylabel('mV')\n    sns.despine(ax=ax)\n\naxes[1, 0].set_xlabel('time (s)')\naxes[1, 1].set_xlabel('time (s)')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# R-peak detection on a 30-second segment\nsegment = ecg_arr_p[0 : 30 * TARGET_SR]\nwd, m = hp.process(hp.scale_data(segment), sample_rate=TARGET_SR)\n\nplt.figure(figsize=(14, 4))\nhp.plotter(wd, m, title='R-peak detection — arrhythmia record 106 (30 s)')\nplt.show()\n\nprint('\\nMeasures from this segment:')\nfor k, v in m.items():\n    print(f'  {k}: {v:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Windowing"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We divide each recording into fixed-length windows with 50% overlap. Each window will produce one feature vector.\n\nA window of at least 30 seconds is needed to compute HRV reliably — it must contain enough R-peaks to estimate frequency-domain features after RR interpolation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "WINDOW_SEC  = 30\nOVERLAP     = 0.5\nWINDOW_SAMP = WINDOW_SEC * TARGET_SR\nSTEP_SAMP   = int(WINDOW_SAMP * (1 - OVERLAP))\n\ndef get_windows(ecg, window_samp=WINDOW_SAMP, step_samp=STEP_SAMP):\n    \"\"\"Slide a fixed window over the ECG signal.\"\"\"\n    windows = []\n    for start in range(0, len(ecg) - window_samp, step_samp):\n        windows.append(ecg[start : start + window_samp])\n    return windows\n\nwins_arr = get_windows(ecg_arr_p)\nwins_nsr = get_windows(ecg_nsr_p)\n\nprint(f'Arrhythmia windows: {len(wins_arr)}')\nprint(f'Normal windows:     {len(wins_nsr)}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# illustrate the windowing scheme\nfig, ax = plt.subplots(figsize=(14, 2.5))\nt_full = np.arange(len(ecg_arr_p)) / TARGET_SR / 60\n\nax.plot(t_full, ecg_arr_p, color='tomato', linewidth=0.4, alpha=0.7)\n\n# draw first 6 window borders\ncolors_w = ['steelblue', 'darkorange']\nfor i in range(min(6, len(wins_arr))):\n    x0 = i * STEP_SAMP / TARGET_SR / 60\n    x1 = (i * STEP_SAMP + WINDOW_SAMP) / TARGET_SR / 60\n    ax.axvspan(x0, x1, alpha=0.15, color=colors_w[i % 2])\n\nax.set_xlabel('time (min)')\nax.set_title(f'Windowing — {WINDOW_SEC}s window, {int(OVERLAP*100)}% overlap', fontsize=11)\nsns.despine(ax=ax)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Feature extraction"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Time-domain features"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_time_domain(rr_intervals):\n    \"\"\"\n    rr_intervals: RR intervals in milliseconds.\n    Returns SDNN, RMSSD, pNN50, mean HR, mean RR.\n    \"\"\"\n    if len(rr_intervals) < 5:\n        return None\n    rr   = np.array(rr_intervals)\n    diff = np.diff(rr)\n    return {\n        'mean_rr' : np.mean(rr),\n        'sdnn'    : np.std(rr),\n        'rmssd'   : np.sqrt(np.mean(diff ** 2)),\n        'pnn50'   : np.sum(np.abs(diff) > 50) / len(diff) * 100,\n        'mean_hr' : 60000 / np.mean(rr),\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Frequency-domain features"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The RR series is interpolated to a uniform grid and the Power Spectral Density is estimated with Welch's method. We integrate in the standard HRV bands:\n- **LF** (0.04–0.15 Hz): combined sympathetic and parasympathetic activity\n- **HF** (0.15–0.4 Hz): parasympathetic activity / respiratory sinus arrhythmia\n- **LF/HF ratio**: autonomic balance index — increases under stress or arrhythmia"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_frequency_domain(rr_intervals, fs_interp=4.0):\n    \"\"\"\n    Interpolates the RR series and computes PSD-based HRV bands.\n    fs_interp: resampling frequency (Hz). Standard for HRV is 4 Hz.\n    \"\"\"\n    if len(rr_intervals) < 10:\n        return None\n    rr   = np.array(rr_intervals)\n    t_rr = np.cumsum(rr) / 1000.0\n    t_rr -= t_rr[0]\n\n    t_uniform = np.arange(t_rr[0], t_rr[-1], 1.0 / fs_interp)\n    if len(t_uniform) < 16:\n        return None\n\n    interp_fn  = interp1d(t_rr, rr, kind='cubic', fill_value='extrapolate')\n    rr_uniform = interp_fn(t_uniform)\n\n    freqs, psd = welch(rr_uniform, fs=fs_interp,\n                       nperseg=min(256, len(rr_uniform)))\n\n    def band_power(f_lo, f_hi):\n        idx = (freqs >= f_lo) & (freqs < f_hi)\n        return np.trapz(psd[idx], freqs[idx])\n\n    vlf   = band_power(0.003, 0.04)\n    lf    = band_power(0.04,  0.15)\n    hf    = band_power(0.15,  0.40)\n    total = vlf + lf + hf\n\n    return {\n        'lf_power'    : lf,\n        'hf_power'    : hf,\n        'lf_hf_ratio' : lf / hf if hf > 0 else 0,\n        'lf_norm'     : lf / (total - vlf) * 100 if (total - vlf) > 0 else 0,\n        'hf_norm'     : hf / (total - vlf) * 100 if (total - vlf) > 0 else 0,\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Non-linear features (Poincaré plot)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The Poincaré plot maps each RR interval against the next one. SD1 reflects short-term (beat-to-beat) variability driven by the parasympathetic system. SD2 reflects longer-term variability."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_nonlinear(rr_intervals):\n    \"\"\"SD1, SD2 and SD2/SD1 ratio from the Poincaré plot.\"\"\"\n    if len(rr_intervals) < 5:\n        return None\n    rr  = np.array(rr_intervals)\n    rr1 = rr[:-1]\n    rr2 = rr[1:]\n    sd1 = np.std((rr2 - rr1) / np.sqrt(2))\n    sd2 = np.std((rr2 + rr1) / np.sqrt(2))\n    return {\n        'sd1'     : sd1,\n        'sd2'     : sd2,\n        'sd2_sd1' : sd2 / sd1 if sd1 > 0 else 0,\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# visualize Poincare plot for both conditions\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\nfor ax, (wins, label, color) in zip(axes, [\n        (wins_nsr, 'normal',     'steelblue'),\n        (wins_arr, 'arrhythmia', 'tomato')]):\n    # use first window that processes cleanly\n    for win in wins:\n        try:\n            wd, _ = hp.process(hp.scale_data(win), sample_rate=TARGET_SR)\n            rr = np.array(wd['RR_list_cor'])\n            if len(rr) > 10:\n                ax.scatter(rr[:-1], rr[1:], alpha=0.5, s=15, color=color)\n                ax.set_title(f'Poincaré — {label}', fontsize=11)\n                ax.set_xlabel('RR_n (ms)')\n                ax.set_ylabel('RR$_{n+1}$ (ms)')\n                ax.set_aspect('equal')\n                sns.despine(ax=ax)\n                break\n        except:\n            continue\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Building the feature matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_all_features(ecg_window, sample_rate=TARGET_SR):\n    \"\"\"Run HeartPy on one window and combine all three feature domains.\"\"\"\n    try:\n        wd, m = hp.process(hp.scale_data(ecg_window),\n                           sample_rate=sample_rate,\n                           clean_rr=True)\n        rr = np.array(wd['RR_list_cor'])\n        if len(rr) < 10:\n            return None\n        td = extract_time_domain(rr)\n        fd = extract_frequency_domain(rr)\n        nl = extract_nonlinear(rr)\n        if any(d is None for d in [td, fd, nl]):\n            return None\n        return {**td, **fd, **nl}\n    except:\n        return None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# build feature matrix for the two loaded records\nrecords = []\nfor wins, label, subj in [(wins_nsr, 'normal', '16265'),\n                           (wins_arr, 'arrhythmia', '106')]:\n    for win in wins:\n        feats = extract_all_features(win)\n        if feats is not None:\n            feats['label']   = label\n            feats['subject'] = subj\n            records.append(feats)\n\ndf_single = pd.DataFrame(records)\nprint(df_single['label'].value_counts())\ndf_single.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# compare feature distributions between conditions\nfeature_cols = [c for c in df_single.columns if c not in ['label', 'subject']]\n\nfig, axes = plt.subplots(3, 4, figsize=(16, 9))\naxes = axes.flatten()\n\npalette = {'normal': 'steelblue', 'arrhythmia': 'tomato'}\n\nfor ax, feat in zip(axes, feature_cols):\n    sns.boxplot(data=df_single, x='label', y=feat,\n                palette=palette, ax=ax, width=0.5)\n    ax.set_title(feat, fontsize=10)\n    ax.set_xlabel('')\n    sns.despine(ax=ax)\n\nfor ax in axes[len(feature_cols):]:\n    ax.set_visible(False)\n\nplt.suptitle('Feature distributions — records 106 (arrhythmia) vs 16265 (normal)',\n             fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Multi-record feature matrix"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We repeat the pipeline for all selected records to build a dataset with enough subjects for Leave-One-Subject-Out evaluation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "all_records = []\n\nrecord_list = (\n    [(rec, 'mitdb',  SR_ARRHYTHMIA, 'arrhythmia') for rec in ARRHYTHMIA_RECORDS] +\n    [(rec, 'nsrdb',  SR_NORMAL,     'normal')      for rec in NORMAL_RECORDS]\n)\n\nfor rec_id, db, sr, label in record_list:\n    try:\n        ecg   = load_record(rec_id, db, sr)\n        ecg_p = preprocess(ecg, sr)\n        wins  = get_windows(ecg_p)\n        n_ok  = 0\n        for win in wins:\n            feats = extract_all_features(win)\n            if feats is not None:\n                feats['label']   = label\n                feats['subject'] = rec_id\n                all_records.append(feats)\n                n_ok += 1\n        print(f'{rec_id:6s} ({label:11s}): {n_ok} windows')\n    except Exception as e:\n        print(f'{rec_id:6s}: skipped ({e})')\n\ndf_all = pd.DataFrame(all_records)\nprint(f'\\nTotal: {len(df_all)} windows — {df_all[\"subject\"].nunique()} subjects')\ndf_all.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# class balance per subject\npivot = df_all.groupby(['subject', 'label']).size().unstack(fill_value=0)\npivot.plot(kind='bar', figsize=(14, 4),\n           color=['tomato', 'steelblue'], width=0.7)\nplt.ylabel('# windows')\nplt.xlabel('record')\nplt.xticks(rotation=45)\nplt.legend(title='condition')\nsns.despine()\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Classification"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Leave-One-Subject-Out (LOSO) evaluation"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In previous units we split data randomly into train/test. For physiological data this is problematic: if windows from the same subject appear in both sets, the model learns individual ECG morphology rather than generalizable patterns — inflating accuracy artificially.\n\nLeave-One-Subject-Out (LOSO) is a stricter protocol: on each fold one subject is held out entirely as the test set. This simulates deploying the model on a new, unseen person — a much more realistic evaluation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "feature_cols = [c for c in df_all.columns if c not in ['label', 'subject']]\n\nle = LabelEncoder()\nX      = df_all[feature_cols].values\ny      = le.fit_transform(df_all['label'].values)\ngroups = df_all['subject'].values\n\nlogo = LeaveOneGroupOut()\n\nclassifiers = {\n    'Decision Tree' : DecisionTreeClassifier(random_state=42),\n    'kNN'           : KNeighborsClassifier(n_neighbors=5),\n    'Random Forest' : RandomForestClassifier(n_estimators=100, random_state=42),\n}\n\nresults = {name: {'y_true': [], 'y_pred': []} for name in classifiers}\n\nfor train_idx, test_idx in logo.split(X, y, groups):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n    scaler  = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test  = scaler.transform(X_test)\n\n    for name, clf in classifiers.items():\n        clf.fit(X_train, y_train)\n        pred = clf.predict(X_test)\n        results[name]['y_true'].extend(y_test)\n        results[name]['y_pred'].extend(pred)\n\nfor name in classifiers:\n    y_true = np.array(results[name]['y_true'])\n    y_pred = np.array(results[name]['y_pred'])\n    f1  = f1_score(y_true, y_pred, average='macro')\n    acc = np.mean(y_true == y_pred)\n    print(f'{name:20s}  accuracy: {acc:.3f}   F1 (macro): {f1:.3f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Confusion matrices"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\nclass_names = le.classes_\n\nfor ax, name in zip(axes, classifiers):\n    cm = confusion_matrix(results[name]['y_true'],\n                          results[name]['y_pred'])\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm_norm,\n                                   display_labels=class_names)\n    disp.plot(ax=ax, colorbar=False, cmap='Blues')\n    ax.set_title(name, fontsize=11)\n\nplt.suptitle('Confusion matrices — LOSO (% per true class)', fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Feature importance (Random Forest)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# refit on all data for stable importances\nscaler_full = StandardScaler()\nX_scaled = scaler_full.fit_transform(X)\nclassifiers['Random Forest'].fit(X_scaled, y)\n\nimportances = pd.Series(\n    classifiers['Random Forest'].feature_importances_,\n    index=feature_cols\n).sort_values(ascending=True)\n\nplt.figure(figsize=(8, 5))\nimportances.plot(kind='barh', color='steelblue')\nplt.xlabel('importance')\nplt.title('Feature importance — Random Forest')\nsns.despine()\nplt.tight_layout()\nplt.show()"
  }
 ]
}